## Current Projects and Achievements

### Fine-Tuning BERT Models on Custom Data
I have fine-tuned popular NLP models such as BERT on custom datasets, applying advanced techniques to optimize their performance for domain-specific tasks. I have also written blog on fine-tuning on LLMs. Will publish it shortly.

### Fine-Tuning Open-Source Models
I have successfully fine-tuned open-source models like LLAMA(Quantized and Non-Quantized), Mistral and Zephyer for various use cases. Using Parameter Efficient Fine-Tuning (PEFT) methods like LoRA and QLoRA, I achieved powerful results with reduced computational requirements.

## Completing and uploading this week: 

### Reinforcement Learning from Human Feedback (RLHF) and Optimization Methods
I explored RLHF to improve language model performance, implementing advanced optimization techniques like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). These efforts have resulted in enhanced model quality, and the findings will be shared soon.
