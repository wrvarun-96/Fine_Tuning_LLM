## Current Projects and Achievements

### Fine-Tuning BERT Models on Custom Data
I have fine-tuned popular NLP models such as BERT on custom datasets, applying advanced techniques to optimize their performance for domain-specific tasks. I have also written blog on fine-tuning on LLMs. Will publish it shortly.

### Fine-Tuned Open-Source Models
I have successfully fine-tuned open-source models like LLAMA(Quantized and Non-Quantized), Mistral and Zephyer for various use cases. Using Parameter Efficient Fine-Tuning (PEFT) methods like LoRA and QLoRA, I achieved powerful results with reduced computational requirements.

### Fine-Tuned Mistral Models(7B_Instruct and Small_Instruct)
I performed fine-tuning on mistral 4bit models and compared the results based on time and memory consumption using Unsloth, and GPTQ models. Below barchart shows the result i have gained.
![Unknown](https://github.com/user-attachments/assets/c01a7000-6f32-4ebc-80a1-c57a02df1c12)

<img width="1187" alt="Screenshot 2024-10-30 at 1 26 23 AM" src="https://github.com/user-attachments/assets/2a2d6b64-1924-4122-9fef-0a5cbff6efdd">



## Completing and uploading this week: 

### Reinforcement Learning from Human Feedback (RLHF) and Optimization Methods
I explored RLHF to improve language model performance, implementing advanced optimization techniques like Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). These efforts have resulted in enhanced model quality, and the findings will be shared soon.
